{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\Large \\frac{1}{\\ell}\\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, приближающий целевой признак, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$\\Large y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$\\Large X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$\\Large X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В начале напишем простую функцию для записи ответов в текстовый файл. Ответами будут числа, полученные в ходе решения этого задания, округленные до 3 знаков после запятой. Полученные файлы после выполнения задания надо отправить в форму на странице задания на Coursera.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, filename):\n",
    "    with open(filename, 'w') as f_out:\n",
    "        f_out.write(str(round(answer, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adver_data = pd.read_csv('C:/11/advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.7</td>\n",
       "      <td>48.9</td>\n",
       "      <td>75.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>57.5</td>\n",
       "      <td>32.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>11.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120.2</td>\n",
       "      <td>19.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>13.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>199.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>21.2</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>66.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>24.2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>214.7</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23.8</td>\n",
       "      <td>35.1</td>\n",
       "      <td>65.9</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>97.5</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.2</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>204.1</td>\n",
       "      <td>32.9</td>\n",
       "      <td>46.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>195.4</td>\n",
       "      <td>47.7</td>\n",
       "      <td>52.9</td>\n",
       "      <td>22.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>67.8</td>\n",
       "      <td>36.6</td>\n",
       "      <td>114.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>281.4</td>\n",
       "      <td>39.6</td>\n",
       "      <td>55.8</td>\n",
       "      <td>24.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>69.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>18.3</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>147.3</td>\n",
       "      <td>23.9</td>\n",
       "      <td>19.1</td>\n",
       "      <td>14.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>218.4</td>\n",
       "      <td>27.7</td>\n",
       "      <td>53.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>237.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>23.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13.2</td>\n",
       "      <td>15.9</td>\n",
       "      <td>49.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>228.3</td>\n",
       "      <td>16.9</td>\n",
       "      <td>26.2</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>62.3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>18.3</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>262.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>142.9</td>\n",
       "      <td>29.3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>240.1</td>\n",
       "      <td>16.7</td>\n",
       "      <td>22.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>248.8</td>\n",
       "      <td>27.1</td>\n",
       "      <td>22.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>70.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>40.8</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>50.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>18.4</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>164.5</td>\n",
       "      <td>20.9</td>\n",
       "      <td>47.4</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>19.6</td>\n",
       "      <td>20.1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>168.4</td>\n",
       "      <td>7.1</td>\n",
       "      <td>12.8</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>222.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>13.1</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>276.9</td>\n",
       "      <td>48.9</td>\n",
       "      <td>41.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>248.4</td>\n",
       "      <td>30.2</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>170.2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>35.2</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>276.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>23.7</td>\n",
       "      <td>11.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>165.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>12.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>156.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>218.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>27.4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>56.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>29.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>287.6</td>\n",
       "      <td>43.0</td>\n",
       "      <td>71.8</td>\n",
       "      <td>26.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>253.8</td>\n",
       "      <td>21.3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>205.0</td>\n",
       "      <td>45.1</td>\n",
       "      <td>19.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>139.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>26.6</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>191.1</td>\n",
       "      <td>28.7</td>\n",
       "      <td>18.2</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>286.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>15.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>18.7</td>\n",
       "      <td>12.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>39.5</td>\n",
       "      <td>41.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>75.5</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>17.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>31.6</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>166.8</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>19.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>149.7</td>\n",
       "      <td>35.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>38.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>94.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>177.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>283.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>25.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>232.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>13.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  Radio  Newspaper  Sales  bias\n",
       "1    230.1   37.8       69.2   22.1     1\n",
       "2     44.5   39.3       45.1   10.4     1\n",
       "3     17.2   45.9       69.3    9.3     1\n",
       "4    151.5   41.3       58.5   18.5     1\n",
       "5    180.8   10.8       58.4   12.9     1\n",
       "6      8.7   48.9       75.0    7.2     1\n",
       "7     57.5   32.8       23.5   11.8     1\n",
       "8    120.2   19.6       11.6   13.2     1\n",
       "9      8.6    2.1        1.0    4.8     1\n",
       "10   199.8    2.6       21.2   10.6     1\n",
       "11    66.1    5.8       24.2    8.6     1\n",
       "12   214.7   24.0        4.0   17.4     1\n",
       "13    23.8   35.1       65.9    9.2     1\n",
       "14    97.5    7.6        7.2    9.7     1\n",
       "15   204.1   32.9       46.0   19.0     1\n",
       "16   195.4   47.7       52.9   22.4     1\n",
       "17    67.8   36.6      114.0   12.5     1\n",
       "18   281.4   39.6       55.8   24.4     1\n",
       "19    69.2   20.5       18.3   11.3     1\n",
       "20   147.3   23.9       19.1   14.6     1\n",
       "21   218.4   27.7       53.4   18.0     1\n",
       "22   237.4    5.1       23.5   12.5     1\n",
       "23    13.2   15.9       49.6    5.6     1\n",
       "24   228.3   16.9       26.2   15.5     1\n",
       "25    62.3   12.6       18.3    9.7     1\n",
       "26   262.9    3.5       19.5   12.0     1\n",
       "27   142.9   29.3       12.6   15.0     1\n",
       "28   240.1   16.7       22.9   15.9     1\n",
       "29   248.8   27.1       22.9   18.9     1\n",
       "30    70.6   16.0       40.8   10.5     1\n",
       "..     ...    ...        ...    ...   ...\n",
       "171   50.0   11.6       18.4    8.4     1\n",
       "172  164.5   20.9       47.4   14.5     1\n",
       "173   19.6   20.1       17.0    7.6     1\n",
       "174  168.4    7.1       12.8   11.7     1\n",
       "175  222.4    3.4       13.1   11.5     1\n",
       "176  276.9   48.9       41.8   27.0     1\n",
       "177  248.4   30.2       20.3   20.2     1\n",
       "178  170.2    7.8       35.2   11.7     1\n",
       "179  276.7    2.3       23.7   11.8     1\n",
       "180  165.6   10.0       17.6   12.6     1\n",
       "181  156.6    2.6        8.3   10.5     1\n",
       "182  218.5    5.4       27.4   12.2     1\n",
       "183   56.2    5.7       29.7    8.7     1\n",
       "184  287.6   43.0       71.8   26.2     1\n",
       "185  253.8   21.3       30.0   17.6     1\n",
       "186  205.0   45.1       19.6   22.6     1\n",
       "187  139.5    2.1       26.6   10.3     1\n",
       "188  191.1   28.7       18.2   17.3     1\n",
       "189  286.0   13.9        3.7   15.9     1\n",
       "190   18.7   12.1       23.4    6.7     1\n",
       "191   39.5   41.1        5.8   10.8     1\n",
       "192   75.5   10.8        6.0    9.9     1\n",
       "193   17.2    4.1       31.6    5.9     1\n",
       "194  166.8   42.0        3.6   19.6     1\n",
       "195  149.7   35.6        6.0   17.3     1\n",
       "196   38.2    3.7       13.8    7.6     1\n",
       "197   94.2    4.9        8.1    9.7     1\n",
       "198  177.0    9.3        6.4   12.8     1\n",
       "199  283.6   42.0       66.2   25.5     1\n",
       "200  232.1    8.6        8.7   13.4     1\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adver_data.loc[:,['TV', 'Radio', 'Newspaper']]\n",
    "adver_data['bias']=1\n",
    "adver_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.967425</td>\n",
       "      <td>0.979066</td>\n",
       "      <td>1.774493</td>\n",
       "      <td>22.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.194379</td>\n",
       "      <td>1.080097</td>\n",
       "      <td>0.667903</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.512360</td>\n",
       "      <td>1.524637</td>\n",
       "      <td>1.779084</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.051919</td>\n",
       "      <td>1.214806</td>\n",
       "      <td>1.283185</td>\n",
       "      <td>18.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.393196</td>\n",
       "      <td>-0.839507</td>\n",
       "      <td>1.278593</td>\n",
       "      <td>12.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TV     Radio  Newspaper  Sales  bias\n",
       "1  0.967425  0.979066   1.774493   22.1     1\n",
       "2 -1.194379  1.080097   0.667903   10.4     1\n",
       "3 -1.512360  1.524637   1.779084    9.3     1\n",
       "4  0.051919  1.214806   1.283185   18.5     1\n",
       "5  0.393196 -0.839507   1.278593   12.9     1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for c in ['TV', 'Radio', 'Newspaper']: #итерируемся по всем признакам, включая Sales\n",
    "    mean, std = adver_data[c].mean(), adver_data[c].std() #mean и std\n",
    "    adver_data[c]=(adver_data[c] - mean)/std #нормируем данные\n",
    "adver_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = adver_data.values\n",
    "y = adver_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение. Для определенности, используйте методы mean и std векторов NumPy (реализация std в Pandas может отличаться). Обратите внимание, что в numpy вызов функции .mean() без параметров возвращает среднее по всем элементам массива, а не по столбцам, как в pandas. Чтобы произвести вычисление по столбцам, необходимо указать параметр axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#means, stds = # Ваш код здесь\n",
    "import numpy as np\n",
    "X['TV'] = (X['TV'] - np.mean(X['TV']))/np.std(X['TV'])\n",
    "X['Radio'] = (X['Radio'] - np.mean(X['Radio']))/np.std(X['Radio'])\n",
    "X['Newspaper'] = (X['Newspaper'] - np.mean(X['Newspaper']))/np.std(X['Newspaper'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.69852266e-01,   9.81522472e-01,   1.77894547e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.19737623e+00,   1.08280781e+00,   6.69578760e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.51615499e+00,   1.52846331e+00,   1.78354865e+00,\n",
       "          1.00000000e+00],\n",
       "       [  5.20496822e-02,   1.21785493e+00,   1.28640506e+00,\n",
       "          1.00000000e+00],\n",
       "       [  3.94182198e-01,  -8.41613655e-01,   1.28180188e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.61540845e+00,   1.73103399e+00,   2.04592999e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.04557682e+00,   6.43904671e-01,  -3.24708413e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -3.13436589e-01,  -2.47406325e-01,  -8.72486994e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.61657614e+00,  -1.42906863e+00,  -1.36042422e+00,\n",
       "          1.00000000e+00],\n",
       "       [  6.16042873e-01,  -1.39530685e+00,  -4.30581584e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -9.45155670e-01,  -1.17923146e+00,  -2.92486143e-01,\n",
       "          1.00000000e+00],\n",
       "       [  7.90028350e-01,   4.96973404e-02,  -1.22232878e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.43908760e+00,   7.99208859e-01,   1.62704048e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -5.78501712e-01,  -1.05768905e+00,  -1.07502697e+00,\n",
       "          1.00000000e+00],\n",
       "       [  6.66253447e-01,   6.50657027e-01,   7.11007392e-01,\n",
       "          1.00000000e+00],\n",
       "       [  5.64664612e-01,   1.65000572e+00,   1.02862691e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -9.25304978e-01,   9.00494200e-01,   3.84117072e+00,\n",
       "          1.00000000e+00],\n",
       "       [  1.56887609e+00,   1.10306488e+00,   1.16211917e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -9.08957349e-01,  -1.86635121e-01,  -5.64073843e-01,\n",
       "          1.00000000e+00],\n",
       "       [  3.00679600e-03,   4.29449843e-02,  -5.27248393e-01,\n",
       "          1.00000000e+00],\n",
       "       [  8.33232798e-01,   2.99534513e-01,   1.05164281e+00,\n",
       "          1.00000000e+00],\n",
       "       [  1.05509347e+00,  -1.22649795e+00,  -3.24708413e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.56286250e+00,  -4.97243498e-01,   8.76721921e-01,\n",
       "          1.00000000e+00],\n",
       "       [  9.48833887e-01,  -4.29719938e-01,  -2.00422516e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -9.89527805e-01,  -7.20071247e-01,  -5.64073843e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.35285385e+00,  -1.33453565e+00,  -5.08835667e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -4.83714657e-02,   4.07572210e-01,  -8.26455181e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.08662104e+00,  -4.43224650e-01,  -3.52327501e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.18820988e+00,   2.59020377e-01,  -3.52327501e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -8.92609721e-01,  -4.90491142e-01,   4.71641962e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.70316018e+00,   3.40048650e-01,   5.82118314e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -3.98677796e-01,  -3.95958157e-01,   3.70371972e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -5.82004775e-01,  -1.46958277e+00,  -2.55016247e-02,\n",
       "          1.00000000e+00],\n",
       "       [  1.38438142e+00,  -2.20396901e-01,  -1.39264649e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -5.99520091e-01,  -1.47633512e+00,  -1.06582061e+00,\n",
       "          1.00000000e+00],\n",
       "       [  1.67747105e+00,  -1.29402151e+00,  -1.01518562e+00,\n",
       "          1.00000000e+00],\n",
       "       [  1.39956136e+00,   1.38666383e+00,  -1.17629696e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -8.44734522e-01,   1.76479577e+00,   6.97197848e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.21372386e+00,   2.32010953e-01,   2.09260624e-01,\n",
       "          1.00000000e+00],\n",
       "       [  9.45330823e-01,   9.74770116e-01,   6.65620024e-02,\n",
       "          1.00000000e+00],\n",
       "       [  6.47570443e-01,  -6.50927121e-02,   4.81492770e-02,\n",
       "          1.00000000e+00],\n",
       "       [  3.49810063e-01,   6.84418807e-01,   3.74975153e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.71133400e+00,   2.99534513e-01,  -1.32359877e+00,\n",
       "          1.00000000e+00],\n",
       "       [  6.98948705e-01,  -1.00367020e+00,  -1.91216154e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.42390765e+00,   1.64487393e-01,   5.86721496e-01,\n",
       "          1.00000000e+00],\n",
       "       [  3.27623995e-01,  -5.15880000e-02,   4.35460956e-02,\n",
       "          1.00000000e+00],\n",
       "       [ -6.69581357e-01,  -9.02384859e-01,   2.36879713e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.08428567e+00,   1.23135965e+00,  -5.54867481e-01,\n",
       "          1.00000000e+00],\n",
       "       [  9.35989321e-01,  -5.03995854e-01,   8.90531465e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -9.35814168e-01,  -7.80842451e-01,   2.87514708e-01,\n",
       "          1.00000000e+00],\n",
       "       [  6.16042873e-01,  -1.36154507e+00,   1.86244718e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -5.44638766e-01,  -9.22641928e-01,  -1.24074150e+00,\n",
       "          1.00000000e+00],\n",
       "       [  8.09879042e-01,   1.24486436e+00,   4.16403786e-01,\n",
       "          1.00000000e+00],\n",
       "       [  4.15200577e-01,   1.54872038e+00,   1.29561142e+00,\n",
       "          1.00000000e+00],\n",
       "       [  1.35051848e+00,   3.73810430e-01,  -6.74550196e-01,\n",
       "          1.00000000e+00],\n",
       "       [  6.05533683e-01,   1.76479577e+00,   1.35545278e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.63175608e+00,   3.26543937e-01,   4.99261050e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.26606546e-01,  -2.74415749e-01,  -6.42327927e-01,\n",
       "          1.00000000e+00],\n",
       "       [  7.44488528e-01,   1.77830048e+00,   3.28943340e-01,\n",
       "          1.00000000e+00],\n",
       "       [  7.43320840e-01,   4.21076922e-01,  -9.78360166e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.09228433e+00,  -1.43582099e+00,  -4.21375221e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.33417085e+00,   1.31238792e+00,   1.11148417e+00,\n",
       "          1.00000000e+00],\n",
       "       [  1.07727954e+00,  -5.24252922e-01,  -1.49787521e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -5.17781948e-01,   4.27829278e-01,  -1.01978880e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.86158622e-01,   1.31914027e+00,  -7.61366196e-02,\n",
       "          1.00000000e+00],\n",
       "       [ -9.11292725e-01,  -9.42898996e-01,  -1.36502740e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.34917564e+00,   9.02114765e-02,  -1.30518604e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -9.04082253e-02,  -5.91776482e-01,  -9.36931533e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.05509347e+00,   2.86029801e-01,  -9.00106083e-01,\n",
       "          1.00000000e+00],\n",
       "       [  8.14549794e-01,   1.39341619e+00,  -1.54390703e-01,\n",
       "          1.00000000e+00],\n",
       "       [  6.07869059e-01,   4.95352838e-01,   3.74975153e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -4.34876116e-01,  -6.05281194e-01,   5.27524584e-02,\n",
       "          1.00000000e+00],\n",
       "       [ -1.40405696e+00,   6.57409383e-01,  -5.18042030e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -2.06009314e-01,  -1.18598381e+00,   3.43397329e-02,\n",
       "          1.00000000e+00],\n",
       "       [  7.74848409e-01,   9.02114765e-02,  -8.03439274e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.51965805e+00,   1.37991148e+00,   2.70878810e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.39588315e+00,  -1.46283041e+00,  -4.53597491e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -3.09933525e-01,   3.53553362e-01,  -7.52804279e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.65394214e+00,   4.48086346e-01,  -9.73756984e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -3.62479475e-01,  -1.05093669e+00,  -3.43121138e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -8.24883830e-01,   2.32010953e-01,  -3.79946589e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.08311798e+00,  -1.29402151e+00,   2.92117889e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -8.37728396e-01,  -2.00139833e-01,   8.95779092e-02,\n",
       "          1.00000000e+00],\n",
       "       [ -9.18298852e-01,   1.43393033e+00,   2.32276531e-01,\n",
       "          1.00000000e+00],\n",
       "       [  7.76016097e-01,   1.33264499e+00,   1.49419267e-01,\n",
       "          1.00000000e+00],\n",
       "       [  5.38975481e-01,  -3.28434597e-01,   1.61783412e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -8.26051518e-01,   2.86029801e-01,  -6.69947015e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -4.24366926e-01,   1.17058844e+00,   1.50275459e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -6.85928986e-01,   1.50982681e-01,   1.97227908e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -4.34876116e-01,   1.65675807e+00,   9.59579186e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.48792614e-01,  -1.24000266e+00,  -9.78360166e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.38303858e+00,  -1.46958277e+00,   1.12593816e-01,\n",
       "          1.00000000e+00],\n",
       "       [  8.25058983e-01,   6.91171163e-01,   1.30942097e+00,\n",
       "          1.00000000e+00],\n",
       "       [  1.21273132e+00,   8.93741844e-01,   1.92164409e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -4.62900623e-01,  -6.25538262e-01,  -9.04709264e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.89836839e-01,   5.62876398e-01,   1.02862691e+00,\n",
       "          1.00000000e+00],\n",
       "       [  5.90353742e-01,  -1.33453565e+00,  -1.13486833e+00,\n",
       "          1.00000000e+00],\n",
       "       [  4.42057396e-01,  -1.52873340e-01,  -3.93756133e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.66579418e+00,   1.28537849e+00,   9.50372823e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.38283424e-01,   1.24486436e+00,   7.06404211e-01,\n",
       "          1.00000000e+00],\n",
       "       [  8.79940308e-01,  -1.28051680e+00,   8.85928284e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.74402926e+00,   8.80237132e-01,   3.23815396e+00,\n",
       "          1.00000000e+00],\n",
       "       [  1.55486384e+00,  -8.88880147e-01,  -4.21375221e-01,\n",
       "          1.00000000e+00],\n",
       "       [  4.77088029e-01,  -4.09462869e-01,  -5.82486569e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.06443498e+00,   7.45190011e-01,  -1.16248742e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.06755854e-01,   1.56222509e+00,   1.30942097e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.42507534e+00,  -8.28108943e-01,  -3.93111688e-02,\n",
       "          1.00000000e+00],\n",
       "       [ -6.61407543e-01,  -1.55061104e+00,  -3.38517957e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.56403019e+00,  -1.54385868e+00,  -2.28041604e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.26527727e+00,   2.45515665e-01,  -1.15328106e+00,\n",
       "          1.00000000e+00],\n",
       "       [  9.19641692e-01,  -1.01717491e+00,   1.19434143e+00,\n",
       "          1.00000000e+00],\n",
       "       [  1.10530405e+00,   9.95027184e-01,  -3.38517957e-01,\n",
       "          1.00000000e+00],\n",
       "       [  3.34630122e-01,  -5.31005278e-01,  -1.29597968e+00,\n",
       "          1.00000000e+00],\n",
       "       [  7.30476274e-01,  -1.79882765e-01,  -9.13915627e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -8.03865450e-01,   1.58923451e+00,   1.81641536e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -8.40063771e-01,   7.92456503e-01,   1.01942054e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -9.15759131e-02,  -6.05281194e-01,  -2.28041604e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -8.24883830e-01,  -1.51684926e+00,  -7.25185191e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -2.49213762e-01,   9.20751268e-01,   2.23926360e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.49046586e+00,  -4.90491142e-01,  -3.79946589e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -6.70544700e-02,   2.38763309e-01,   7.20213755e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.49747198e+00,  -1.05606848e-01,   9.13547372e-01,\n",
       "          1.00000000e+00],\n",
       "       [  8.98623313e-01,  -1.40881156e+00,  -6.88359740e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -2.79573643e-01,   7.65447079e-01,  -8.35661544e-01,\n",
       "          1.00000000e+00],\n",
       "       [  9.62846140e-01,   6.10142891e-01,   2.00910454e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -6.98773552e-01,  -7.74090095e-01,  -2.14232060e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.62591764e+00,   1.05579839e+00,   9.22753735e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -7.80511695e-01,  -1.57086811e+00,  -9.82963347e-01,\n",
       "          1.00000000e+00],\n",
       "       [  8.55418865e-01,   1.73778635e+00,  -1.25915423e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.02105537e+00,  -7.60585383e-01,   5.77515133e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.70882347e+00,   1.10306488e+00,  -1.00597925e+00,\n",
       "          1.00000000e+00],\n",
       "       [  1.37971067e+00,  -1.37504978e+00,   5.72911952e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.61891151e+00,   2.65772733e-01,  -1.30978922e+00,\n",
       "          1.00000000e+00],\n",
       "       [  8.49580427e-01,   6.91171163e-01,   6.69578760e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.28612050e+00,   1.03554132e+00,   1.61323094e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.15300409e+00,   1.60273923e+00,  -1.01518562e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.41806922e+00,   1.06255074e+00,  -9.78360166e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.47896413e+00,   3.80562786e-01,   1.34164324e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.21489154e+00,   1.77992105e-01,  -4.62803854e-01,\n",
       "          1.00000000e+00],\n",
       "       [  4.42057396e-01,   1.39341619e+00,  -1.32820195e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -8.59914463e-01,  -4.22967582e-01,  -8.12645637e-01,\n",
       "          1.00000000e+00],\n",
       "       [  5.44813920e-01,   8.19465927e-01,   2.07354907e+00,\n",
       "          1.00000000e+00],\n",
       "       [  8.57754241e-01,   6.70914095e-01,   3.38149702e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -4.95595880e-01,  -1.18598381e+00,   1.77038355e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -5.93681653e-01,  -5.71519414e-01,   3.84181516e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -7.87313476e-02,  -1.44257334e+00,  -9.92169710e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.08662104e+00,  -1.07794612e+00,  -1.00597925e+00,\n",
       "          1.00000000e+00],\n",
       "       [  1.12281936e+00,   1.73778635e+00,   6.32753309e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.27327593e+00,   1.15033137e+00,  -8.58677450e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.19504085e+00,   1.71239749e-01,  -4.58200672e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.56070228e+00,  -6.32290618e-01,   2.96721070e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -3.04095087e-01,  -1.00367020e+00,   8.35293289e-01,\n",
       "          1.00000000e+00],\n",
       "       [  5.90353742e-01,   2.43084817e-03,  -7.52804279e-01,\n",
       "          1.00000000e+00],\n",
       "       [  2.83251860e-01,   1.10981724e+00,   3.28943340e-01,\n",
       "          1.00000000e+00],\n",
       "       [  4.75920341e-01,  -1.46120984e-01,  -9.69153803e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.66912209e+00,  -7.87594807e-01,  -1.14407469e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -6.20538471e-01,   1.36640677e+00,   9.18150553e-01,\n",
       "          1.00000000e+00],\n",
       "       [  3.21989902e-02,  -1.48308748e+00,  -2.87882962e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.58037782e+00,   9.20751268e-01,   6.74181942e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.79152496e-01,  -3.28434597e-01,   1.86244718e-01,\n",
       "          1.00000000e+00],\n",
       "       [  2.97264113e-01,  -3.48691665e-01,   6.72064478e-03,\n",
       "          1.00000000e+00],\n",
       "       [ -7.16288868e-01,   8.46475352e-01,   8.62912377e-01,\n",
       "          1.00000000e+00],\n",
       "       [  4.82926468e-01,  -3.48691665e-01,  -2.28041604e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.92172214e-01,   9.13998912e-01,  -1.06582061e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -3.48467222e-01,  -5.78271770e-01,  -1.15788424e+00,\n",
       "          1.00000000e+00],\n",
       "       [  1.02123053e+00,  -1.34128800e+00,   2.49704176e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.50798117e+00,   9.68017760e-01,  -4.12168859e-01,\n",
       "          1.00000000e+00],\n",
       "       [  6.97781017e-01,  -1.21974559e+00,  -5.13438849e-01,\n",
       "          1.00000000e+00],\n",
       "       [  7.98202165e-01,   2.26879163e-02,   1.24497643e+00,\n",
       "          1.00000000e+00],\n",
       "       [  1.60273904e+00,  -8.55118367e-01,  -1.11185242e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.13315340e+00,  -7.87594807e-01,  -5.59470662e-01,\n",
       "          1.00000000e+00],\n",
       "       [  2.03849092e-01,  -1.59625696e-01,   7.75451931e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.48813048e+00,  -2.13644545e-01,  -6.23915201e-01,\n",
       "          1.00000000e+00],\n",
       "       [  2.49388915e-01,  -1.09145083e+00,  -8.17248818e-01,\n",
       "          1.00000000e+00],\n",
       "       [  8.79940308e-01,  -1.34128800e+00,  -8.03439274e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.51633014e+00,   1.73103399e+00,   5.17673775e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.18353913e+00,   4.68343414e-01,  -4.72010216e-01,\n",
       "          1.00000000e+00],\n",
       "       [  2.70407294e-01,  -1.04418434e+00,   2.13863806e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.51399477e+00,  -1.41556392e+00,  -3.15502050e-01,\n",
       "          1.00000000e+00],\n",
       "       [  2.16693657e-01,  -8.95632503e-01,  -5.96296113e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.11601758e-01,  -1.39530685e+00,  -1.02439198e+00,\n",
       "          1.00000000e+00],\n",
       "       [  8.34400486e-01,  -1.20624088e+00,  -1.45184340e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.06075676e+00,  -1.18598381e+00,  -3.93111688e-02,\n",
       "          1.00000000e+00],\n",
       "       [  1.64127273e+00,   1.33264499e+00,   1.89862818e+00,\n",
       "          1.00000000e+00],\n",
       "       [  1.24659427e+00,  -1.32616272e-01,  -2.55016247e-02,\n",
       "          1.00000000e+00],\n",
       "       [  6.76762637e-01,   1.47444446e+00,  -5.04232486e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -8.80728498e-02,  -1.42906863e+00,  -1.82009791e-01,\n",
       "          1.00000000e+00],\n",
       "       [  5.14454038e-01,   3.67058074e-01,  -5.68677025e-01,\n",
       "          1.00000000e+00],\n",
       "       [  1.62258973e+00,  -6.32290618e-01,  -1.23613832e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.49863967e+00,  -7.53833027e-01,  -3.29311594e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -1.25576062e+00,   1.20435022e+00,  -1.13947151e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -8.35393020e-01,  -8.41613655e-01,  -1.13026515e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.51615499e+00,  -1.29402151e+00,   4.81492770e-02,\n",
       "          1.00000000e+00],\n",
       "       [  2.30705910e-01,   1.26512143e+00,  -1.24074150e+00,\n",
       "          1.00000000e+00],\n",
       "       [  3.10313024e-02,   8.32970639e-01,  -1.13026515e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.27094056e+00,  -1.32103093e+00,  -7.71217005e-01,\n",
       "          1.00000000e+00],\n",
       "       [ -6.17035408e-01,  -1.24000266e+00,  -1.03359834e+00,\n",
       "          1.00000000e+00],\n",
       "       [  3.49810063e-01,  -9.42898996e-01,  -1.11185242e+00,\n",
       "          1.00000000e+00],\n",
       "       [  1.59456522e+00,   1.26512143e+00,   1.64085003e+00,\n",
       "          1.00000000e+00],\n",
       "       [  9.93206022e-01,  -9.90165488e-01,  -1.00597925e+00,\n",
       "          1.00000000e+00]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.96985227,  0.98152247,  1.77894547,  1.        ],\n",
       "       [-1.19737623,  1.08280781,  0.66957876,  1.        ],\n",
       "       [-1.51615499,  1.52846331,  1.78354865,  1.        ],\n",
       "       [ 0.05204968,  1.21785493,  1.28640506,  1.        ],\n",
       "       [ 0.3941822 , -0.84161366,  1.28180188,  1.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import numpy as np\n",
    "#X = np.hstack # Ваш код здесь\n",
    "X = np.hstack([X, np.ones([X.shape[0], 1], dtype=np.int32)])\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения). Не используйте в этой функции циклы - тогда она будет вычислительно неэффективной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mserror(y, y_pred):\n",
    "    return((y-y_pred)**2 # считаем квадраты отклонения \n",
    "          ).sum()/len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Запишите ответ в файл '1.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer1 = # Ваш код здесь\n",
    "print(answer1)\n",
    "write_answer_to_file(answer1, '1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    return np.dot(np.linalg.inv(X),y)  # Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Last 2 dimensions of the array must be square",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-0feadc053bbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnorm_eq_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormal_equation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm_eq_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-dba779dab896>\u001b[0m in \u001b[0;36mnormal_equation\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mnormal_equation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Ваш код здесь\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    506\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_makearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m     \u001b[0m_assertRankAtLeast2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m     \u001b[0m_assertNdSquareness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_assertNdSquareness\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Last 2 dimensions of the array must be square'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_assertFinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Last 2 dimensions of the array must be square"
     ]
    }
   ],
   "source": [
    "norm_eq_weights = normal_equation(X, y)\n",
    "print(norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Запишите ответ в файл '2.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer2 = # Ваш код здесь\n",
    "print(answer2)\n",
    "write_answer_to_file(answer2, '2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    return np.dot(X,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения? Запишите ответ в файл '3.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.92908869   2.79906919  -0.02259517  14.0225    ]\n",
      "2.78412631451\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C/11/3.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-4f15e03fd2cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0manswer3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmserror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madver_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSales\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mwrite_answer_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'C/11/3.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#ZZ = np.linalg.pinv(X)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-c0cfcc3cc3a4>\u001b[0m in \u001b[0;36mwrite_answer_to_file\u001b[1;34m(answer, filename)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwrite_answer_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf_out\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mf_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C/11/3.txt'"
     ]
    }
   ],
   "source": [
    "def normal_equation(X, y):\n",
    "    a = np.dot(X.T, X) # преобразуем левую часть\n",
    "    b = np.dot(X.T, y) # преобразуем правую часть\n",
    "    res = np.linalg.solve(a, b) # решаем систему\n",
    "    return res\n",
    "\n",
    "FeatureMatrix = adver_data[['TV', 'Radio', 'Newspaper', 'bias']].values\n",
    "TargetMatrix  = adver_data.Sales.values\n",
    "\n",
    "norm_eq_weights= normal_equation(FeatureMatrix, TargetMatrix)\n",
    "print(norm_eq_weights)\n",
    "\n",
    "y_pred = np.dot(adver_data[['TV', 'Radio', 'Newspaper', 'bias']].values, norm_eq_weights)\n",
    "answer3 = mserror(adver_data.Sales.values, y_pred)\n",
    "print(answer3)\n",
    "write_answer_to_file(answer3, 'C/11/3.txt')\n",
    "\n",
    "#ZZ = np.linalg.pinv(X)\n",
    "#yy = np.hstack(y)\n",
    "#ZZ*yy\n",
    "#yy=y.as_matrix\n",
    "#w = np.dot(ZZ,yy)\n",
    "#answer3 = # Ваш код здесь\n",
    "#print(answer3)\n",
    "#write_answer_to_file(answer3, '3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов. Наша реализация функции будет явно написана для данных с 3 признаками, но несложно модифицировать для любого числа признаков, можете это сделать.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    N = X.shape[0]                   # всего обьектов (нормировка)\n",
    "    x = X[train_ind]                 # текуший случайный k обьект \n",
    "    y_pred = linear_prediction(x, w) # предсказание для к случайного обьекта \n",
    "    rs = (y_pred - y[train_ind])     # регрессионый остаток для k обьекта \n",
    "    \n",
    "    grad0 = 2.0/N*x[0]*rs\n",
    "    grad1 = 2.0/N*x[1]*rs\n",
    "    grad2 = 2.0/N*x[2]*rs\n",
    "    grad3 = 2.0/N*x[3]*rs\n",
    "    return  w - eta * np.array([grad0, grad1, grad2, grad3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- max_weight_dist - максимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        \n",
    "        new_w = stochastic_gradient_step(X, y, w, random_ind, eta)\n",
    "        \n",
    "        # Считаем ошибку\n",
    "        error = mserror(y, linear_prediction(X, new_w))\n",
    "        errors.append(error)\n",
    "        \n",
    "        weight_dist = np.linalg.norm(w-new_w)\n",
    "        w = new_w\n",
    "        iter_num += 1\n",
    "    print(weight_dist)\n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0261895799e-09\n",
      "Wall time: 2.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(FeatureMatrix, TargetMatrix, [0,0,0,0], eta=0.01, max_iter=1e5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, чему равна ошибка на первых 50 итерациях стохастического градиентного спуска. Видим, что ошибка не обязательно уменьшается на каждой итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'MSE')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxPvtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb5032b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(50), stoch_errors_by_iter[:50])\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь посмотрим на зависимость ошибки от номера итерации для $10^5$ итераций стохастического градиентного спуска. Видим, что алгоритм сходится.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'MSE')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl8HGed5/HPr1uHdVmHJduKLFuy\n4/iKie3IuRM8G0KcDOCEgSVZjgBhw0BgOGaZDczMAjs7QxhezJJw5AAC4UiYwAQSMiEHJs5BiBM5\ncXxgO5ZvxbIl35Zk6+pn/qhHTltuWXKs7upWf9+vV7266unq6p/ssr+qeqqeMuccIiIiA0XCLkBE\nRNKTAkJERBJSQIiISEIKCBERSUgBISIiCSkgREQkIQWEiIgkpIAQEZGEFBAiIpJQTtgFnI7KykpX\nV1cXdhkiIhllxYoVe5xzVUOtl9EBUVdXR2NjY9hliIhkFDPbNpz1dIpJREQSUkCIiEhCCggREUlI\nASEiIgkpIEREJCEFhIiIJKSAEBGRhLIyINbvOsTXH1vPwSM9YZciIpK2sjIgtu/t5I5lm9i6pyPs\nUkRE0lZWBsTkcYUA7NjfGXIlIiLpKysDYlK5D4h9R0KuREQkfWVlQBTn51AyJoddBxUQIiKDycqA\nAKguHcPOg0fDLkNEJG1lcUAU0KIjCBGRQWVtQJxRNoaWAzqCEBEZTPYGRGkBezu6OdrTF3YpIiJp\nKXsDoqwAgJ0HdJpJRCSRrA2ImvL+gNBpJhGRRLI3IPwRxOsHdLOciEgiWRsQE0vHEDF4fb9OMYmI\nJJK1AZEbjTBh7Bhe1ykmEZGEsjYgIDjNpFNMIiKJZXdAlBdoPCYRkUFkdUBMrihk16Gj9PbFwi5F\nRCTtZHVATCovoC/maNGYTCIiJ8jygNBzIUREBpO0gDCzWjN7yszWmdlaM/uMb68wsyfNbKN/Lfft\nZma3m1mTma0yswXJqq3fJH+zXLMudRUROUEyjyB6gb91zs0CLgBuNrPZwC3AUufcdGCpXwa4Cpju\np5uAO5JYGxAMtxExaN6nIwgRkYGSFhDOuRbn3Mt+/jCwDqgBlgD3+tXuBa7x80uAn7jAC0CZmVUn\nqz4I7oWoLi1gh44gREROkJI+CDOrA+YDy4EJzrkWCEIEGO9XqwF2xH2s2bcN3NZNZtZoZo1tbW2n\nXVtwqauOIEREBkp6QJhZMfAfwGedc4dOtmqCNndCg3N3O+canHMNVVVVp13f5IpCtisgREROkNSA\nMLNcgnD4uXPuQd+8u//UkX9t9e3NQG3cxycBO5NZHwQB0Xq4S8+FEBEZIJlXMRnwQ2Cdc+7f4t56\nGLjBz98APBTX/iF/NdMFwMH+U1HJNLkiuNS1WZe6iogcJyeJ274Y+CCw2sxW+rYvAbcCD5jZjcB2\n4L3+vUeBq4EmoBP4SBJrO6bWB8S2vZ2cOb4kFV8pIpIRkhYQzrnnSNyvAHB5gvUdcHOy6hnM1Moi\nADa3dXD5rFR/u4hI+srqO6kByovyGFeUR1Nre9iliIiklawPCIAzxxezsfVw2GWIiKQVBQQwtaqY\nLXs6wi5DRCStKCCAunGF7O/s4WBnT9iliIikDQUEUN/fUb1H/RAiIv0UEMC08cUAOs0kIhJHAQHU\nlhcSMdiqgBAROUYBAeTlRJhUXsiWvbqbWkSknwLCq68sYov6IEREjlFAePWVRWzd00lwQ7eIiCgg\nvLpxhbR39dLW3hV2KSIiaUEB4dVXBVcybd2jfggREVBAHPPGoH3qhxARAQXEMTVlBYzJjWjQPhER\nTwHhRSLG1MpimnQEISICKCCOc+b4YjbuVkCIiIAC4jhnji/m9QNH6OzuDbsUEZHQKSDiTPdjMm1u\n05AbIiIKiDj9g/ZtUj+EiIgCIt6UccGgfZt0JZOIiAIiXn5OlNqKQjZpVFcREQXEQFMri9QHISKC\nAuIEwfOp24nFNGifiGQ3BcQAU6uKONoTo+XQ0bBLEREJlQJigKmV/Ze6qqNaRLKbAmKAaVXBoH26\nkklEsp0CYoCqknxK8nPYpI5qEclyCogBzIyzJpawftehsEsREQmVAiKBWdUlrN91WI8fFZGspoBI\nYFpVMYeP9rKnvTvsUkREQqOASGBalcZkEhFRQCQwtar/8aPqqBaR7KWASKCmrIDi/Bw2qKNaRLKY\nAiIBM2PGxBLW7TocdikiIqFRQAxixsQS1rcc0pVMIpK1FBCDmDWxhENHe9mlMZlEJEslLSDM7B4z\nazWzNXFtXzGz181spZ+ujnvvi2bWZGYbzOzKZNU1XDOrxwKwvkWnmUQkOyXzCOLHwOIE7f/fOTfP\nT48CmNls4Dpgjv/M98wsmsTahnTWhBIA1qmjWkSyVNICwjn3DLBvmKsvAX7hnOtyzm0BmoDzklXb\ncJQW5FJTVsAGdVSLSJYKow/iU2a2yp+CKvdtNcCOuHWafdsJzOwmM2s0s8a2trakFjpzYolOMYlI\n1kp1QNwBTAPmAS3AN327JVg34eVDzrm7nXMNzrmGqqqq5FTpzZhYwqa2drp7Y0n9HhGRdJTSgHDO\n7XbO9TnnYsD3eeM0UjNQG7fqJGBnKmtLZGb1WHpjTkNuiEhWSmlAmFl13OK1QP8VTg8D15lZvpnV\nA9OBF1NZWyKzJgYd1Rr6W0SyUU6yNmxm9wOLgEozawa+DCwys3kEp4+2Ah8HcM6tNbMHgD8DvcDN\nzrm+ZNU2XHWVReRFI0E/xPywqxERSa2kBYRz7voEzT88yfr/DPxzsup5M3KjEc4cX8x6XckkIllI\nd1IPYWa1ni4nItlJATGEmRNL2H2oi/0deniQiGQXBcQQZk70Q27oNJOIZBkFxBBm6komEclSCogh\nVJXkU1GUpzuqRSTrKCCGYGbMnFiiQftEJOsoIIZhbk0p61sO09Ub+q0ZIiIpo4AYhnm1ZXT3xVin\n00wikkUUEMMwb3IZACu37w+5EhGR1FFADEN1aQETx45hxfYDYZciIpIyCohhaqgrp3HrcJ9/JCKS\n+RQQw7SwroKWg0dp3t8ZdikiIimhgBimc6cED79bsU39ECKSHRQQwzRzYgkFuVFeUT+EiGQJBcQw\n5UQjvGVSKS/rSiYRyRIKiFNwwdRxrHn9IAc6NbKriIx+CohTcMn0SmIOlm/R1UwiMvopIE7B3JpS\ncqOmfggRyQoKiFMwJjfK7Oqx6ocQkaxw0oAwsw/EzV884L1PJauodLZgSjmrmg/Q0xcLuxQRkaQa\n6gji83Hz3x7w3kdHuJaMcO6Uco72xFjXouG/RWR0GyogbJD5RMtZof+GuZd1w5yIjHJDBYQbZD7R\nclaoLi2gpqxAVzKJyKiXM8T7M81sFcHRwjQ/j1+emtTK0tiF08axdN1unHOYZeWBlIhkgaECYlZK\nqsgwC+vK+dWKZja1tXPm+JKwyxERSYqTnmJyzm2Ln4B2YAFQ6Zez0vn14wD402adZhKR0Wuoy1wf\nMbOz/Xw1sIbg6qWfmtlnU1BfWpoyrpAzSsfwp017wi5FRCRphuqkrnfOrfHzHwGedM69EzifLL3M\nFcDMuHBaJS9s3kcslpV99SKSBYYKiJ64+cuBRwGcc4eBrL5T7KJp49jX0c2G3YfDLkVEJCmGCogd\nZvZpM7uWoO/hMQAzKwByk11cOmuo8/dDaNgNERmlhgqIG4E5wIeB9znn+kepuwD4URLrSnuTK4J+\niGUb2sIuRUQkKU56matzrhX46wTtTwFPJauoTGBmvHVGFb99tYWevhi5UY17KCKjy0kDwswePtn7\nzrl3jWw5meXiMyu5/8UdrHn9IPMnl4ddjojIiBrqRrkLgR3A/cBysnT8pcH03w/x/Ka9CggRGXWG\nOi8yEfgScDZwG3AFsMc597Rz7ulkF5fuqkrymV09lmc3qh9CREafoe6k7nPOPeacu4GgY7oJWGZm\nnx5qw2Z2j5m1mtmauLYKM3vSzDb613LfbmZ2u5k1mdkqM1twmj9Xylw6vZIV2/bT2d0bdikiIiNq\nyJ5VM8s3s3cDPwNuBm4HHhzGtn8MLB7Qdguw1Dk3HVjqlwGuAqb76SbgjuEUnw4umV5JT5/jRY3u\nKiKjzFBDbdwLPE9wD8RXnXMLnXP/5Jx7fagNO+eeAQb+r7kEuNfP3wtcE9f+Exd4ASjzQ3ukvXOn\nlJMXjfDcRg27ISKjy1Cd1B8EOoCzgL+JG9raAOecG3uK3zfBOddC8OEWMxvv22sIOsP7Nfu2llPc\nfsoV5uWwsL6c55oUECIyugzVBxFxzpX4aWzcVPImwuFkEl0dlXCQIzO7ycwazayxrS09OocvmlbJ\n+l2H2dveFXYpIiIjJtV3d+3uP3XkX1t9ezNQG7feJGBnog045+52zjU45xqqqqqSWuxwXTA1uNxV\nT5kTkdEk1QHxMHCDn78BeCiu/UP+aqYLgIP9p6IywdyaUoryovxRp5lEZBQZqg/iTTOz+4FFQKWZ\nNQNfBm4FHjCzG4HtwHv96o8CVxNcRttJMLR4xsjLiXDhtEqe2dimx5CKyKiRtIBwzl0/yFuXJ1jX\nEVxCm7HeelYlv1+3my17OphaVRx2OSIip00jzI2QRTOCC7Kefi09Os5FRE6XAmKE1FYUMmVcIc/q\nfggRGSUUECPoL2aM5/lNe+jo0rAbIpL5FBAj6O1zJnC0J6bTTCIyKiggRtB5dRVUFufx6OqMuUJX\nRGRQCogRlBON8LZZE1i2oY2u3r6wyxEROS0KiBH29jkTaO/q5YXNuqtaRDKbAmKEXTStksK8KI+v\n3RV2KSIip0UBMcLG5EZZNKOKJ9bupi+WcLxBEZGMoIBIgivnTGRPexcrtu0PuxQRkTdNAZEEb5s1\ngcK8KL9+ZcjnKomIpC0FRBIU5efwtlkTeHR1C0e6dTWTiGQmBUSSvG9hLQeP9LBsQ+vQK4uIpCEF\nRJKcX1/BuKI8Hl2jq5lEJDMpIJIkJxrhitkTWLpuN53dGptJRDKPAiKJlsyrobO7j6fWa2wmEck8\nCogkOq++gvLCXJ74s04ziUjmUUAkUTRiXDW3msfX7uLw0Z6wyxEROSUKiCR777mTONoT47evaoRX\nEcksCogkm1dbxowJJfxyxY6wSxEROSUKiCQzM66ZX8Mr2w+wbW9H2OWIiAybAiIFrpl/BhGDXzY2\nh12KiMiwKSBSoLq0gEunV/FA4w66e2NhlyMiMiwKiBT5yMV1tB7u4pFVO8MuRURkWBQQKXLZ9Cqm\njy/mnj9uwTk9J0JE0p8CIkUiEeNDF9Wx5vVDvLz9QNjliIgMSQGRQtfOr6EkP4ef/Glr2KWIiAxJ\nAZFCxfk5vKdhEv+5qoWWg0fCLkdE5KQUECn20YvrccAPnt0SdikiIielgEix2opC3nXOGdy3fDv7\nO7rDLkdEZFAKiBB8YtE0jvT08aPnt4ZdiojIoBQQIThrQglXzpnAvc9vpb1LDxMSkfSkgAjJJxed\nycEjPfzshW1hlyIikpACIiTn1JZx2VlV3P3MZj2SVETSkgIiRJ+5/Ez2dXRz3/LtYZciInICBUSI\nzp1SwUXTxnHHsk3qixCRtBNKQJjZVjNbbWYrzazRt1WY2ZNmttG/lodRW6r978Uz2dvRzfef2Rx2\nKSIixwnzCOIvnHPznHMNfvkWYKlzbjqw1C+PeufUlvGXc6v5/rObaTvcFXY5IiLHpNMppiXAvX7+\nXuCaEGtJqf915Qy6emN8+w8bwy5FROSYsALCAU+Y2Qozu8m3TXDOtQD41/Eh1ZZy9ZVFXLewlvuW\nb9djSUUkbYQVEBc75xYAVwE3m9llw/2gmd1kZo1m1tjW1pa8ClPsM5dPpzfm+MIvV4VdiogIEFJA\nOOd2+tdW4NfAecBuM6sG8K+tg3z2budcg3OuoaqqKlUlJ934sWO4/rzJvLh1H09tSPiji4ikVMoD\nwsyKzKykfx54O7AGeBi4wa92A/BQqmsL21feNZupVUV89eG1dPX2hV2OiGS5MI4gJgDPmdmrwIvA\nfzrnHgNuBa4ws43AFX45q+TnRPnKO+ewdW8n33tqU9jliEiWy0n1FzrnNgPnJGjfC1ye6nrSzWVn\nVXHNvDP47lNNLD57IrOqx4ZdkohkqXS6zFW8L79zDmWFeXzhV6/S0xcLuxwRyVIKiDRUXpTH/7tm\nDmteP8TtS3VvhIiEQwGRphafXc2759dw59Ob+PPOQ2GXIyJZSAGRxv7xHbMpLcjj8w+s1FVNIpJy\nCog0Vl6Ux9f/ai7rdx3mG49tCLscEckyCog0d/msCXzowin84LktPNC4I+xyRCSLpPwyVzl1//iO\n2WzZ08GXHlzNpLICLjqzMuySRCQL6AgiA+RGI3z3/QuYWlXEx3+2gqbWw2GXJCJZQAGRIcaOyeWe\nDy8kPyfKh3/0kp4dISJJp4DIIJPKC/nhDQ3sae/if/6kkaM9urJJRJJHAZFhzqkt41vvm8+rzQf4\n/AMricVc2CWJyCilgMhAi8+eyJeumsWjq3fx979ZjXMKCREZebqKKUN97NJ69nd2871lm6gszudv\n3z4j7JJEZJRRQGQoM+MLV85gT3sX3/5DEwZ87oqzMLOwSxORUUIBkcHMjK+9+y0Yxu1/aKKrL8Yt\ni2cqJERkRCggMlw0Ynzt3XPJzTHuenoze9u7+Zdr55KXo+4lETk9CohRIBIx/mnJ2Ywryue2pRvZ\nvq+TOz9wLhVFeWGXJiIZTL9mjhJmxueuOIvbrpvHyh0HuPq2Z3lh896wyxKRDKaAGGWWzKvhwU9c\nREFelOu//wJfe3Qd3b16Kp2InDoFxCh0dk0pj3z6Eq4/bzJ3PbOZ9975PNv2doRdlohkGAXEKFWU\nn8O/XDuXO96/gC17OrjyW8/w3aeadDQhIsOmgBjlrppbzWOfvYy3nlXFNx7fwHvvfJ6NuzUarIgM\nTQGRBc4oK+CuDzbwvfcvYOveThbf9ixffmgN+zq6wy5NRNKYLnPNIlfPreb8+gr+7cnX+OkL23jw\n5de58dJ6bryknpIxuWGXJyJpxjJ5oLeGhgbX2NgYdhkZ6bXdh/nmExt4fO1uSgtyufGSICiK8vU7\ng8hoZ2YrnHMNQ66ngMhuq5oPcPvSJn6/bjflhbl89OJ6PnjhFMoKdZOdyGilgJBT8sr2/dy+dCNP\nbWijIDfKNfPPYMm8GhbWVRCNaGwnkdFEASFvyvpdh7jnuS08tHInXb0xasoKuHZ+DVfNncjs6rEa\nCFBkFFBAyGnp6OrlD+tbeaBxB39s2kPMweSKQq6aO5Er50xk3qQyIjqyEMlICggZMXvbu3jiz7v5\n3ZpdPN+0h96Yo6Ioj/PrK1hYV8F59RXMqh6rU1EiGUIBIUlxsLOHZa+18vSGNl7cuo/m/UcAKMnP\noaGunIX1FZxfX8HcmjINOS6SpoYbELqmUU5JaWEuS+bVsGReDQA7Dxzhpa37WL5lHy9u2cdTGzYA\nkJ8TYf7kMs6rq2D2GaXMmFhCbXkBOVGFhkim0BGEjKi97V28tHU/L20NAmPtzoPE/C6WF41QX1kU\nTFVFTK0sYtr4YqZWFumyWpEU0hGEhGJccT6Lz57I4rMnAkFn98bWdl7bfZhNre1sautgY+thlq7f\nTU/fG7+cjB2Tw+RxhZxRWkBNeQGTygupLh3D+JJ8qvxUmKfdVSSV9C9OkqooP4d5tWXMqy07rr23\nL8b2fZ1sbutg695gat5/hC17OniuaQ+d3X0nbisvSlVJPuNLxlBZkkdpQR7F+VGK8nMozs+hMC+H\novwoxfk5FOXnUDRguSA3qiuvRE6BAkJCkRONMLWqmKlVxSe855zjQGcPuw4dpe1wF62Hu2jrn9q7\naD10lPW7DnPoSA8dXX0c6TkxTBIxg8LcuEDJj1KUF8yPyYuSnxMhPyfKmNzjX3OjRl5OhLxohNxo\nhJyokRuNEI0YuVEjGomQEzEiZuREjWjEyImYfz9CxIL5qBmRCHHzca8RI2JgGPG3mtiANiN4eqDF\nv697UyRJ0i4gzGwxcBsQBX7gnLs15JIkxcyM8qI8yovymFU99Pp9MUdHdy8dXb10dPX5117au3rp\n7O6jvas3rq2Pzu7euLY+Wg4e5WhvH109Mbp6Y3T19NHVG6O7L/OenREEyhuhYbwRMv0N/W3Boh37\nDMSFz8BAOklAcUKAvfF9A+s51jbM7x/Wzzzc9UZZkF63sJaPXTo1qd+RVgFhZlHgu8AVQDPwkpk9\n7Jz7c7iVSTqLRoyxY3IZO8Ij0sZi7lhQ9PTF6O4NXnv6HH0xR09fjN5YMN8Xc/TGYv7V0dfn3njP\nOWID549rC74r5hwOcA6CuWA+eH1j2cW344619a8w2PvxbcR9xrnjt9H//fHXrzjnEr4f30bcZwZu\nY+DPxbGa3ID332gbjmGvmbnX4gyqsjg/6d+RVgEBnAc0Oec2A5jZL4AlgAJCUi4SMQryohQQDbsU\nkVCk20XpNcCOuOVm33aMmd1kZo1m1tjW1pbS4kREskm6BUSik4THHRw65+52zjU45xqqqqpSVJaI\nSPZJt4BoBmrjlicBO0OqRUQkq6VbQLwETDezejPLA64DHg65JhGRrJRWndTOuV4z+xTwOMFlrvc4\n59aGXJaISFZKq4AAcM49Cjwadh0iItku3U4xiYhImlBAiIhIQhk93LeZtQHb3uTHK4E9I1hOqqn+\ncKn+cGVy/elQ+xTn3JD3CWR0QJwOM2scznjo6Ur1h0v1hyuT68+k2nWKSUREElJAiIhIQtkcEHeH\nXcBpUv3hUv3hyuT6M6b2rO2DEBGRk8vmIwgRETmJrAwIM1tsZhvMrMnMbgm5lnvMrNXM1sS1VZjZ\nk2a20b+W+3Yzs9t93avMbEHcZ27w6280sxvi2s81s9X+M7fbCD5Wy8xqzewpM1tnZmvN7DMZVv8Y\nM3vRzF719X/Vt9eb2XJfy7/7ccEws3y/3OTfr4vb1hd9+wYzuzKuPen7mplFzewVM3sk0+o3s63+\n73elmTX6tkzZf8rM7Fdmtt7/G7gwU2oftuBpUtkzEYzxtAmYCuQBrwKzQ6znMmABsCau7V+BW/z8\nLcDX/fzVwO8IhkW/AFju2yuAzf613M+X+/deBC70n/kdcNUI1l4NLPDzJcBrwOwMqt+AYj+fCyz3\ndT0AXOfb7wQ+4ec/Cdzp568D/t3Pz/b7UT5Q7/evaKr2NeDzwH3AI345Y+oHtgKVA9oyZf+5F/iY\nn88DyjKl9mH/jKn+wrAn/wf+eNzyF4EvhlxTHccHxAag2s9XAxv8/F3A9QPXA64H7oprv8u3VQPr\n49qPWy8JP8dDBI+Lzbj6gULgZeB8gpuYcgbuLwSDSF7o53P8ejZwH+pfLxX7GsGQ+EuB/wY84uvJ\npPq3cmJApP3+A4wFtuD7cTOp9lOZsvEU05BPrUsDE5xzLQD+dbxvH6z2k7U3J2gfcf50xXyC38Iz\npn5/emYl0Ao8SfAb8wHnXG+C7zxWp3//IDBuiPqTva99C/g7IOaXx2VY/Q54wsxWmNlNvi0T9p+p\nQBvwI3967wdmVpQhtQ9bNgbEkE+tS2OD1X6q7SPKzIqB/wA+65w7dLJVB6kntPqdc33OuXkEv4mf\nB8w6yXemVf1m9g6g1Tm3Ir75JN+ZVvV7FzvnFgBXATeb2WUnWTed6s8hODV8h3NuPtBBcEppMOlU\n+7BlY0BkwlPrdptZNYB/bfXtg9V+svZJCdpHjJnlEoTDz51zD2Za/f2ccweAZQTnh8vMrH8o/Pjv\nPFanf78U2DdE/cnc1y4G3mVmW4FfEJxm+lYG1Y9zbqd/bQV+TRDSmbD/NAPNzrnlfvlXBIGRCbUP\nX6rPaYU9EST/ZoLOuP6Otzkh11TH8X0Q3+D4jq5/9fN/yfEdXS/69gqC86HlftoCVPj3XvLr9nd0\nXT2CdRvwE+BbA9ozpf4qoMzPFwDPAu8Afsnxnbyf9PM3c3wn7wN+fg7Hd/JuJujgTdm+BizijU7q\njKgfKAJK4uafBxZn0P7zLDDDz3/F150RtQ/7Z0z1F6bDRHBFwWsE55v/PuRa7gdagB6C3xpuJDgv\nvBTY6F/7dxgDvuvrXg00xG3no0CTnz4S194ArPGf+Q4DOtVOs/ZLCA57VwEr/XR1BtX/FuAVX/8a\n4P/49qkEV5A0Efxnm+/bx/jlJv/+1Lht/b2vcQNxV5ukal/j+IDIiPp9na/6aW3/9jNo/5kHNPr9\n5zcE/8FnRO3DnXQntYiIJJSNfRAiIjIMCggREUlIASEiIgkpIEREJCEFhIiIJKSAkIxjZu3+tc7M\n/scIb/tLA5afH8ntjzQz+7CZfSfsOmR0UkBIJqsDTikgzCw6xCrHBYRz7qJTrCmjDOPPQ7KYAkIy\n2a3Apf5ZAp/zA+99w8xe8mPufxzAzBZZ8NyK+whuUsLMfuMHiFvbP0icmd0KFPjt/dy39R+tmN/2\nGj9G//vitr0s7rkAP080br9f5+sWPH/iNTO71LcfdwRgZo+Y2aL+7/afWWFmvzez8/x2NpvZu+I2\nX2tmj1nw3IYvx23rA/77VprZXf1h4Lf7f81sOcGIrSKJpfrOPE2aTncC2v3rIvzdw375JuAf/Hw+\nwV2u9X69DqA+bt3+O1wLCO5WHRe/7QTf9VcEo71GgQnAdoIhmRcRjIo6ieAXrj8BlySoeRnwTT9/\nNfB7P/9h4Dtx6z0CLPLzDn9XM8E4RU8QPLfiHGBl3OdbCO7g7f9ZGggGHfwtkOvX+x7wobjt/vew\n/x41pf/UP6CXyGjwduAtZvYev1wKTAe6Cca+2RK37t+Y2bV+vtavt/ck274EuN8510cwINvTwELg\nkN92M4AfOrwOeC7BNvoHM1zh1xlKN/CYn18NdDnnesxs9YDPP+mc2+u//0Ffay9wLvCSP6Ap4I2B\n4/oIBlgUOSkFhIwmBnzaOff4cY3BKZuOActvI3h4TqeZLSMYp2iobQ+mK26+j8H/XXUlWKeX40/1\nxtfR45zrHwsn1v9551wsbrRWOHEY6P7hou91zn0xQR1HfdCJnJT6ICSTHSZ41Gm/x4FP+CHIMbOz\n/ENcBioF9vtwmEkwYma/nv7PD/AM8D7fz1FF8KjYF0fgZ9gKzDOziJnVEgx3faqusOBZyAXANcAf\nCQaKe4+ZjYdjz3meMgL1ShZ0VGU3AAAAqUlEQVTREYRkslVAr5m9CvwYuI3g1MvLvqO4jeA/zIEe\nA/7azFYRjF76Qtx7dwOrzOxl59z749p/TdCh+yrBb+h/55zb5QPmdPyRYIjn1QT9By+/iW08B/wU\nOBO4zznXCGBm/0DwtLYIwWjBNwPbTrNeySIazVVERBLSKSYREUlIASEiIgkpIEREJCEFhIiIJKSA\nEBGRhBQQIiKSkAJCREQSUkCIiEhC/wWY/cqLCjwMpgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb56fa58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.89172998e+00,   2.79230916e+00,   6.17758541e-03,\n",
       "         1.39903864e+01])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_grad_desc_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7871848006472946"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Запишите ответ в файл '4.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78718480065\n"
     ]
    }
   ],
   "source": [
    "answer4 = mserror(TargetMatrix, linear_prediction(FeatureMatrix, stoch_grad_desc_weights))\n",
    "print(answer4)\n",
    "write_answer_to_file(answer4, '4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответами к заданию будут текстовые файлы, полученные в ходе этого решения. Обратите внимание, что отправленные файлы не должны содержать пустую строку в конце. Данный нюанс является ограничением платформы Coursera. Мы работаем над исправлением этого ограничения.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
