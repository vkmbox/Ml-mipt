{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример использования библиотеки gensim для тематического моделирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такая полезная теорема Байеса! :)\n",
    "\n",
    "![comic1](http://imgs.xkcd.com/comics/seashell.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JProg\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем данные в формте UCI Bag of Words\n",
    "data = corpora.UciCorpus(\"c:\\\\MyProj\\\\Coursera\\\\Ml-mipt\\\\course3\\\\week4b\\\\pattern\\\\docword.xkcd.txt\", \"c:\\\\MyProj\\\\Coursera\\\\Ml-mipt\\\\course3\\\\week4b\\\\pattern\\\\vocab.xkcd.txt\")\n",
    "dictionary = data.create_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 57s\n"
     ]
    }
   ],
   "source": [
    "# обучение модель\n",
    "%time ldamodel = models.ldamodel.LdaModel(data, id2word=dictionary, num_topics=5, passes=20, alpha=1.25, eta=1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "ldamodel.save(\"c:\\\\MyProj\\\\Coursera\\\\Ml-mipt\\\\course3\\\\week4b\\\\pattern\\\\ldamodel_xkcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка модели\n",
    "ldamodel = models.ldamodel.LdaModel.load(\"c:\\\\MyProj\\\\Coursera\\\\Ml-mipt\\\\course3\\\\week4b\\\\pattern\\\\ldamodel_xkcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 : 0.001*\"b'goggles'\" + 0.001*\"b'jelly'\" + 0.001*\"b'bean'\" + 0.001*\"b'link'\" + 0.001*\"b'acne'\" + 0.001*\"b'found'\" + 0.001*\"b'005'\" + 0.001*\"b'bag'\" + 0.001*\"b'december'\" + 0.001*\"b'24th'\"\n",
      "Topic 1 : 0.002*\"b'exhibit'\" + 0.002*\"b'wait'\" + 0.002*\"b'sagal'\" + 0.001*\"b'peter'\" + 0.001*\"b'list'\" + 0.001*\"b'leopard'\" + 0.001*\"b'base'\" + 0.001*\"b'label'\" + 0.001*\"b'spirit'\" + 0.001*\"b'dont'\"\n",
      "Topic 2 : 0.022*\"b'man'\" + 0.012*\"b'text'\" + 0.011*\"b'person'\" + 0.010*\"b'title'\" + 0.009*\"b'woman'\" + 0.008*\"b'guy'\" + 0.006*\"b'one'\" + 0.006*\"b'girl'\" + 0.005*\"b'just'\" + 0.005*\"b'two'\"\n",
      "Topic 3 : 0.002*\"b'map'\" + 0.002*\"b'part'\" + 0.002*\"b'island'\" + 0.001*\"b'one'\" + 0.001*\"b'within'\" + 0.001*\"b'elaine'\" + 0.001*\"b'relation'\" + 0.001*\"b'roberts'\" + 0.001*\"b'accurate'\" + 0.001*\"b'han'\"\n",
      "Topic 4 : 0.002*\"b'paul'\" + 0.001*\"b'ron'\" + 0.001*\"b'line'\" + 0.001*\"b'anchor'\" + 0.001*\"b'gliese'\" + 0.001*\"b'time'\" + 0.001*\"b'planet'\" + 0.001*\"b'hurricane'\" + 0.001*\"b'reporter'\" + 0.001*\"b'blimp'\"\n"
     ]
    }
   ],
   "source": [
    "# выводим топы слов\n",
    "for t, top_words in ldamodel.print_topics(num_topics=10, num_words=10):\n",
    "    print (\"Topic\", t, \":\", top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348.63854702\n"
     ]
    }
   ],
   "source": [
    "# Вычисляем логарифм перплексии и немного преобразуем, чтобы привести к общепринятому виду\n",
    "perplexity = ldamodel.log_perplexity(list(data))\n",
    "print (2**(-perplexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perp = ldamodel.bound(data)\n",
    "2**(-perp/float(87409))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Добавление в модель новых документов, содержащихся в новом корупсе data2\n",
    "ldamodel.update(data2, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение распределения тем для конкретного документа\n",
    "doc = list(data)[0]\n",
    "ldamodel.get_document_topics(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти люди не знают про тематические модели:\n",
    "\n",
    "![comic2](http://imgs.xkcd.com/comics/the_problem_with_wikipedia.png) | ![comic3](http://imgs.xkcd.com/comics/mystery_news.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
